DART HOWTO0.1, 2004-09-08BrentChun0.12004-09-18Initial version.        This document describes how to use DART, a framework for distributed 
        automated regression testing of large-scale network applications. 
        The current DART implemenation targets Emulab.
      Preliminaries       The current DART implemenation targets Emulab.  Thus,
       order to use DART, you will first need to obtain an account
       on Emulab.  In the rest of this document, we assume that
       your Emulab username is the same as the username on the
       machine where you are running DART from.  
           DART is also currently implemented in Python and has
       been tested primarly on Redhat 7.3 using Python 2.2.
       If your platform differs from this, you may experience
       some Python versioning issues, although, should they
       occur, they are likely to require minor fixes.
    Installing the Software       DART is distributed as a tarball.  Deal with it!  In particular,
       make sure to untar it at the top-level in your home directory.
    Writing a Distributed Test       A DART test consists of several key pieces: (1) a set of files to
       install on each node, (2) an optional preeecution script,
       (3) scripts that run at specific times on subsets of nodes (e.g.,
       a big "run" script that runs on all nodes), (4) a postexecution
       script and (5) a reset script (which cleans out a node and
       allows Emulab experiments to be reused).  In addition, each
       test allow requires a unique name, the name of your Emulab
       project, a unique Emulab experiment name, and several other details.
       We'll work through an example below to make this clearer. Also,
       while this may sound like a lot of work, a significant fraction
       of the above is usually common to multiple tests.   Thus,
       writing a new test often requires just writing the "diff".
    Example: Query Correctness Test on PIER&#60;?xml version="1.0" ?&#62;
&#60;dart&#62;

  &#60;test&#62;
    &#60;name&#62;sq.pier0032&#60;/name&#62;
    &#60;outdir&#62;/tmp/sq.pier0032&#60;/outdir&#62;
  &#60;/test&#62;

  &#60;topology&#62;

    &#60;project&#62;planetlab&#60;/project&#62;
    &#60;experiment&#62;pier0032&#60;/experiment&#62;
    &#60;nsfile&#62;pier0032.ns&#60;/nsfile&#62;
    &#60;eipsfile&#62;pier0032.eips&#60;/eipsfile&#62;
    &#60;iipsfile&#62;pier0032.iips&#60;/iipsfile&#62;

  &#60;/topology&#62;

  &#60;commonfiles&#62;
    &#60;dir&#62;
      &#60;src&#62;/homes/bnc/pier/server&#60;/src&#62;
      &#60;dst&#62;$DART_COMMON_DIR/server&#60;/dst&#62;
    &#60;/dir&#62;
    &#60;dir&#62;
      &#60;src&#62;/homes/bnc/pier/client&#60;/src&#62;
      &#60;dst&#62;$DART_COMMON_DIR/client&#60;/dst&#62;
    &#60;/dir&#62;
    &#60;dir&#62;
      &#60;src&#62;/homes/bnc/pier/sensors&#60;/src&#62;
      &#60;dst&#62;$DART_COMMON_DIR/sensors&#60;/dst&#62;
    &#60;/dir&#62;
    &#60;dir&#62;
      &#60;src&#62;/homes/bnc/pier/scripts&#60;/src&#62;
      &#60;dst&#62;$DART_COMMON_DIR/scripts&#60;/dst&#62;
    &#60;/dir&#62;
    &#60;file&#62;
      &#60;src type="remote"&#62;/proj/planetlab/tarfiles/edata.tar.gz&#60;/src&#62;
      &#60;dst&#62;$DART_COMMON_DIR/edata.tar.gz&#60;/dst&#62;
    &#60;/file&#62;
    &#60;file&#62; 
      &#60;src type="remote"&#62;/proj/planetlab/rpms/j2sdk-1_4_2_03-linux-i586.rpm&#60;/src&#62;
      &#60;dst&#62;$DART_COMMON_DIR/j2sdk-1_4_2_03-linux-i586.rpm&#60;/dst&#62;
    &#60;/file&#62;
  &#60;/commonfiles&#62;

  &#60;preexecution&#62;
    &#60;script&#62;$DART_COMMON_DIR/scripts/preexecution&#60;/script&#62;
  &#60;/preexecution&#62;

  &#60;execution duration="700"&#62;
    &#60;nodegroup&#62;
      &#60;nodes&#62;*&#60;/nodes&#62;
      &#60;cmd&#62;$DART_COMMON_DIR/scripts/startPier&#60;/cmd&#62;
    &#60;/nodegroup&#62;
    &#60;nodegroup&#62;
      &#60;nodes&#62;*&#60;/nodes&#62;
      &#60;cmd&#62;$DART_COMMON_DIR/scripts/startsensors&#60;/cmd&#62;
    &#60;/nodegroup&#62;

    &#60;!-- Wait 120 seconds for PIER, 10 seconds between each test --&#62;
    &#60;nodegroup&#62;
      &#60;nodes&#62;0&#60;/nodes&#62;
      &#60;cmd time="120"&#62;$DART_COMMON_DIR/scripts/sq.selectall/runclient -b 1 1&#60;/cmd&#62;
    &#60;/nodegroup&#62;
    &#60;nodegroup&#62;
      &#60;nodes&#62;0&#60;/nodes&#62;
      &#60;cmd time="250"&#62;$DART_COMMON_DIR/scripts/sq.selectall/runclient -b 4 1&#60;/cmd&#62;
    &#60;/nodegroup&#62;
    &#60;nodegroup&#62;
      &#60;nodes&#62;0&#60;/nodes&#62;
      &#60;cmd time="380"&#62;$DART_COMMON_DIR/scripts/sq.selectall/runclient -b 16 1&#60;/cmd&#62;
    &#60;/nodegroup&#62;
    &#60;nodegroup&#62;
      &#60;nodes&#62;0&#60;/nodes&#62;
      &#60;cmd time="510"&#62;$DART_COMMON_DIR/scripts/sq.selectall/runclient -b 64 1&#60;/cmd&#62;
    &#60;/nodegroup&#62;

  &#60;/execution&#62;

  &#60;postexecution&#62;
    &#60;script&#62;$DART_COMMON_DIR/scripts/sq.selectall/postexecution&#60;/script&#62;
  &#60;/postexecution&#62;

  &#60;reset&#62;
    &#60;script&#62;$DART_COMMON_DIR/scripts/reset&#60;/script&#62;
  &#60;/reset&#62;

&#60;/dart&#62;    The test section includes two things.  First, a unique test name and
    second, a local directory to store test output from all nodes in the
    test.  Under the output directory, node output will be stored under
    subdirectories named by virtual nodes numbers ranging from 0 to n - 1. 
    Usually I just store all output in /tmp under /tmp/testname as
    in the example.
      The topology section includes Emulab information and names of
    useful related files.  The project is the name of the Emulab
    project you are part of (recall the Preliminaries section). 
    The experiment and nsfile correspond to the specific Emulab
    topology the distributed test is to be run on.  nsfile is
    an Emulab topology file generated by dart using the mktopologies
    command. (NOTE: add more on this) while experiment is the
    name of the experiment corresponding to that file.  When
    running multiple tests that use the same topology, it's
    convenenient to use the same experiment and nsfile names.
    This will ensure that the topology gets cached rather than
    reinstantiated each time.  Lastly, the eipsfile and iipsfile
    are local files (that DART creates) that store the list of
    external IP addresses and internal IP addresses for the
    nodes in your  Emulab experiment. These can be useful
    if you need/want to ssh into specific nodes to examine what
    is going on (e.g., when debugging a distributed test for
    the first time).
      The commonfiles section specifies a set of local files/directories (dir
    for directories, file for files) to be transfered to each node.   
    For each file/directory, src specifies a local path of the
    relevant data and dst specifes a remote path on Emulab nodes. 
    Specifying type="remote" specifies that src should be taken relative
    to the destination node.  This is useful if you are repeatedly 
    transferring common files over the wide-area that are large and
    are better served off of Emulab's local NFS (which all nodes
    mount).  For example, in the above, the JDK's src is a path to
    an NFS mounted directory on an Emulab node and dst is a local
    path on that Emulab node.
      The preexecution section specifies a script to run on all nodes
    after all files/directories in commonfiles have been transferred
    over.  In the preexecution script above, we install the JDK RPM
    and copy static data (to be queried) off of Emulab's NFS server.
    This is entirely application-specific and is optional (omit this
    section if you don't want it).
      The execution section is where the main action takes place. It
    takes a required attribute called duration which specifies how
    long the test should run.  Within the execution section, one
    or more nodegroup sections can be specified. Each nodegroup
    section specifies a commond to run at a specified time on a 
    a specific subset of nodes. The time is specified in seconds
    since the test start.  The nodes are specified by a comma
    separated node numbers (0 to n-1).  Two conveniences are provided:
    a wildcard * which means all nodes and ranges of nodes (e.g., 0-3).
    In the PIER example, there are three things going on. First,
    we start the servers up by calling startPier.  This starts up
    PIER.  Second, we start the sensors that have data to be queried.
    Third, we issue a sequence of queries by a single client in
    succession.  Note that after starting PIER, we wait 120 seconds before 
    issuing the first such query.  This is to give the DHT time 
    to stabilize and to allow the multicast tree for query dissemination
    to form. In the test code itself (i.e., the client code), output
    is written to a well-known directory (/tmp/out).  This output
    will then be collected by the master node (node 0) which 
    we can then run a postexecution script against to check the results.
       The postexecution section specifies a script to run on the master
     node (node 0) after everything in the execution section has
     completed.  Note that, in contrast to the preexecution section,
     this runs only on the master.  The idea here is that after the
     test completes, all the output data (from /tmp/out on each node)
     from each node will be collected on the master in a well-known
     directory (/tmp/allout on the master).  We then run a
     postexecution script to compute the results of the test. 
        Finally, the reset script specifies how to reset a node so
      that an Emulab experiment can be reused across tests that
      use the same topology.  This might kill all application processes
      and remove all application files for example.
   Running a Distributed Test      Given a test file (or set of test files) such as the one in the previous
      section (e.g., suppose it was named sq.pier.0032.xml and we have
      another test file named mq.pier.0032.xml), we run it as follows:
   bin/dart sq.pier0032.xml mq.pier0032.xml      Assuming we followed the output directory conventions described
      earlier, this command will instantiate the necessary Emulab
      experiments (reused cached ones if possible), set up distributed
      tests, run them, and collect the output in directories on your
      local machine. 
   